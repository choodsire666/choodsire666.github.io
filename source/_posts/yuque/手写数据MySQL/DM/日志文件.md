---
title: 日志文件
urlname: uhy686i29cqv
date: '2024-04-26 16:38:18'
updated: '2024-05-06 19:40:30'
description: 'MYDB提供了崩溃后的数据恢复功能，DM层在每次对底层数据进行操作时，都会记录一条日志到磁盘上。在数据库崩溃之后，再次重启时，可以根据日志的内容，恢复数据文件，保证其一致性；日志读写日志的二进制文件，按照如下的格式进行排布：[XChecksum][Log1][Log2][Log3]...[Lo...'
---
MYDB提供了崩溃后的数据恢复功能，DM层在每次对底层数据进行操作时，都会记录一条日志到磁盘上。在数据库崩溃之后，再次重启时，可以根据日志的内容，恢复数据文件，保证其一致性；
## 日志读写
日志的二进制文件，按照如下的格式进行排布：
```
[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]
```
其中 **XChecksum** 是一个四字节的整数，是对后续所有日志计算的校验和。**Log1 ~ LogN** 是常规的日志数据，**BadTail** 是在数据库崩溃时，没有来得及写完的日志数据，这个 **BadTail** 不一定存在。
每条日志的格式如下：
```
[Size][Checksum][Data]
[0, 0, 0, 3] [3, -112, -4, 93] [97, 97, 97]
[0, 0, 0, 3] [14, 40, -23, -38] [98, 98, 98]
[0, 0, 0, 3] [24, -64, -41, 87] [99, 99, 99]
```
其中，**Size** 是一个四字节整数，标识了 **Data** 段的字节数。**Checksum** 则是该条日志的校验和。
### 单条文件的校验和
对每条日志进行校验和，就可以得到总文件的校验和了
```java
private int calChecksum(int xCheck, byte[] log) {
    for (byte b : log) {
        xCheck = xCheck * SEED + b; //seed = 13331
    }
    return xCheck;
}
```
### 日志文件的创建及初始化
在日志文件创建时create()会初始化 [XChecksum] 的字节大小，默认为0；
```java
// class: src/main/java/top/guoziyang/mydb/backend/dm/logger/Logger.java
ByteBuffer buf = ByteBuffer.wrap(Parser.int2Byte(0)); // 将0转换成四字节的数字
try {
    fc.position(0);
    fc.write(buf); //将其写入到文件
    fc.force(false);
} catch (IOException e) {
    Panic.panic(e);
}
```
日志文件创建完需要打开时，会调用open()方法，并读取日志文件的[XChecksum]以及去除BadTail；
```java
void init() {
    long size = 0;
    try {
        size = file.length(); //读取文件大小
    } catch (IOException e) {
        Panic.panic(e);
    }
    if (size < 4) { //若文件大小小于4，证明日志文件创建出现问题
        Panic.panic(Error.BadLogFileException);
    }

    ByteBuffer raw = ByteBuffer.allocate(4); //创建一个容量为4的ByteBuffer
    try {
        fc.position(0);
        fc.read(raw); //读取四字节大小的内容
    } catch (IOException e) {
        Panic.panic(e);
    }
    int xChecksum = Parser.parseInt(raw.array()); //将其转换成int整数
    this.fileSize = size;
    this.xChecksum = xChecksum; //赋值给当前对象

    checkAndRemoveTail(); //检查是否需要去除BadTail
}
```
### checkAndRemoveTail()
在打开一个日志文件时，需要首先校验日志文件的 **XChecksum**，并移除文件尾部可能存在的 **BadTail**，由于 **BadTail** 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/5e76448c37238b68351a6beb59f6f7fb.png)
```java
// 检查并移除bad tail
private void checkAndRemoveTail() {
    // 将当前位置重置为文件的开始位置
    // [XChecksum][Log1][Log2]...[LogN][BadTail] --> [Log1][Log2]...[LogN][BadTail]
    rewind();

    // 初始化校验和为 0
    int xCheck = 0;

    // 循环读取日志，直到没有更多的日志可以读取
    while (true) {
        // 读取下一条日志
        byte[] log = internNext();

        // 如果读取到的日志为 null，说明没有更多的日志可以读取，跳出循环
        if (log == null) break;

        // 计算校验和
        xCheck = calChecksum(xCheck, log);
    }

    // 比较计算得到的校验和和文件中的校验和，如果不相等，说明日志已经被破坏，抛出异常
    if (xCheck != xChecksum) {
        Panic.panic(Error.BadLogFileException);
    }

    // 尝试将文件截断到当前位置，移除 "bad tail"
    try {
        truncate(position);
    } catch (Exception e) {
        // 如果发生异常，调用 Panic.panic 方法处理异常
        Panic.panic(e);
    }

    // 尝试将文件的读取位置设置为当前位置
    try {
        file.seek(position);
    } catch (IOException e) {
        // 如果发生 IO 异常，调用 Panic.panic 方法处理异常
        Panic.panic(e);
    }

    // 将当前位置重置为文件的开始位置
    rewind();
}
```
### next()
Logger 被实现成迭代器模式，通过 next() 方法，不断地从文件中读取下一条日志，并将其中的 Data 解析出来并返回。next() 方法的实现主要依靠 internNext();
```java
@Override
public byte[] next() {
    lock.lock();
    try {
        byte[] log = internNext();
        if (log == null) return null;
        // 返回日志文件 data
        return Arrays.copyOfRange(log, OF_DATA, log.length);
    } finally {
        lock.unlock();
    }
}
```
### internNext()
画的不规范，大概意思知道即可
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/51bdacec1194de37ed8a1140bc3acde5.png)
```java
/**
 * 获取下一条日志
 */
private byte[] internNext() {
    // 检查当前位置是否已经超过了文件的大小，如果超过了，说明没有更多的日志可以读取，返回 null
    if (position + OF_DATA >= fileSize) {
        return null;
    }

    // 创建一个大小为 4 的 ByteBuffer，用于读取日志的大小
    ByteBuffer tmp = ByteBuffer.allocate(4);
    try {
        // 将文件通道的位置设置为当前位置
        fc.position(position);
        // 从文件通道中读取 4 个字节的数据到 ByteBuffer 中，即Size日志文件的大小
        fc.read(tmp);
    } catch (IOException e) {
        // 如果发生 IO 异常，调用 Panic.panic 方法处理异常
        Panic.panic(e);
    }

    // 使用 Parser.parseInt 方法将读取到的 4 个字节的数据转换为 int 类型，得到日志的大小
    int size = Parser.parseInt(tmp.array());

    // 检查当前位置加上日志的大小是否超过了文件的大小，如果超过了，说明日志不完整，返回 null
    if (position + size + OF_DATA > fileSize) {
        return null;
    }

    // 创建一个大小为 OF_DATA + size 的 ByteBuffer，用于读取完整的日志
    ByteBuffer buf = ByteBuffer.allocate(OF_DATA + size);
    try {
        // 将文件通道的位置设置为当前位置
        fc.position(position);
        // 从文件通道中读取 OF_DATA + size 个字节的数据到 ByteBuffer 中
        // 读取整条日志 [Size][Checksum][Data]
        fc.read(buf);
    } catch (IOException e) {
        // 如果发生 IO 异常，调用 Panic.panic 方法处理异常
        Panic.panic(e);
    }

    // 将 ByteBuffer 中的数据转换为字节数组
    byte[] log = buf.array();

    // 计算日志数据的校验和
    int checkSum1 = calChecksum(0, Arrays.copyOfRange(log, OF_DATA, log.length));
    // 从日志中读取校验和
    int checkSum2 = Parser.parseInt(Arrays.copyOfRange(log, OF_CHECKSUM, OF_DATA));

    // 比较计算得到的校验和和日志中的校验和，如果不相等，说明日志已经被破坏，返回 null
    if (checkSum1 != checkSum2) {
        return null;
    }

    // 更新当前位置
    position += log.length;

    // 返回读取到的日志
    return log;
}
```
### log()
向日志文件写入日志时，也是首先将数据包裹成日志格式，写入文件后，再更新文件的校验和，更新校验和时，会刷新缓冲区，保证内容写入磁盘。
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/e70aba5a537d1b5b6beebcfe718b9452.png)
```java
@Override
public void log(byte[] data) {
    // 解析成一条完整的log日志
    byte[] log = wrapLog(data);
    ByteBuffer buf = ByteBuffer.wrap(log);
    lock.lock();
    try {
        //写入到指定位置
        fc.position(fc.size());
        fc.write(buf);
    } catch (IOException e) {
        Panic.panic(e);
    } finally {
        lock.unlock();
    }
    // 更新总校验值
    updateXChecksum(log);
}

/**
 * 更新总校验值
 */
private void updateXChecksum(byte[] log) {
    //计算总校验值
    this.xChecksum = calChecksum(this.xChecksum, log);
    try {
        fc.position(0);
        fc.write(ByteBuffer.wrap(Parser.int2Byte(xChecksum)));
        fc.force(false);
    } catch (IOException e) {
        Panic.panic(e);
    }
}

/**
* 将数据解析成完整log
*/
private byte[] wrapLog(byte[] data) {
    // 使用 calChecksum 方法计算数据的校验和，然后将校验和转换为字节数组
    byte[] checksum = Parser.int2Byte(calChecksum(0, data));
    // 将数据的长度转换为字节数组
    byte[] size = Parser.int2Byte(data.length);
    // 使用 Bytes.concat 方法将 size、checksum 和 data 连接成一个新的字节数组，然后返回这个字节数组
    return Bytes.concat(size, checksum, data);
}
```
## 恢复策略
在MYDB中，有两条规则限制了数据库的操作，以便于恢复日志；

1. **正在进行的事务，不会读取其他任何未提交的事务产生的数据**
2. **正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据**

根据上方的两条规则，MYDB日志的恢复也分为两种：

1. **通过****redo log****重做所有崩溃时已经完成（****committed 或 aborted****）的事务**
2. **通过****undo log****撤销所有崩溃时未完成（****active****）的事务 **

**redo：**

1. 正序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx

**undo：**

1. 倒序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx

注：对于 redo log 和 undo log，可以学习该文章（[图解MySQL-日志篇]()）
### 日志格式
首先规定两种日志的格式类型：
```java
public class Recover {
    private static final byte LOG_TYPE_INSERT = 0;
    private static final byte LOG_TYPE_UPDATE = 1;

    // updateLog:
    // [LogType] [XID] [UID] [OldRaw] [NewRaw]
    
    // insertLog:
    // [LogType] [XID] [Pgno] [Offset] [Raw]
}
```
### 重做所有已完成的事务
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/ace1f0c8438f2b3047ab4bf60b182463.png)
```java
private static void redoTranscations(TransactionManager tm, Logger lg, PageCache pc) {
    // 重置日志文件的读取位置到开始
    lg.rewind();
    // 循环读取日志文件中的所有日志记录
    while (true) {
        // 读取下一条日志记录
        byte[] log = lg.next();
        // 如果读取到的日志记录为空，表示已经读取到日志文件的末尾，跳出循环
        if (log == null) break;
        // 判断日志记录的类型
        if (isInsertLog(log)) {
            // 如果是插入日志，解析日志记录，获取插入日志信息
            InsertLogInfo li = parseInsertLog(log);
            // 获取事务ID
            long xid = li.xid;
            // 如果当前事务已经提交，进行重做操作
            if (!tm.isActive(xid)) {
                doInsertLog(pc, log, REDO);
            }
        } else {
            // 如果是更新日志，解析日志记录，获取更新日志信息
            UpdateLogInfo xi = parseUpdateLog(log);
            // 获取事务ID
            long xid = xi.xid;
            // 如果当前事务已经提交，进行重做操作
            if (!tm.isActive(xid)) {
                doUpdateLog(pc, log, REDO);
            }
        }
    }
}
```
### 撤销所有未完成的事务
流程图只是简易表达了意思，详细请查看代码；
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/ae952f5c880c00c12c26e98ed822f323.png)
```java
private static void undoTranscations(TransactionManager tm, Logger lg, PageCache pc) {
    // 创建一个用于存储日志的映射，键为事务ID，值为日志列表
    Map<Long, List<byte[]>> logCache = new HashMap<>();
    // 将日志文件的读取位置重置到开始
    lg.rewind();
    // 循环读取日志文件中的所有日志记录
    while (true) {
        // 读取下一条日志记录
        byte[] log = lg.next();
        // 如果读取到的日志记录为空，表示已经读取到日志文件的末尾，跳出循环
        if (log == null) break;
        // 判断日志记录的类型
        if (isInsertLog(log)) {
            // 如果是插入日志，解析日志记录，获取插入日志信息
            InsertLogInfo li = parseInsertLog(log);
            // 获取事务ID
            long xid = li.xid;
            // 如果当前事务仍然活跃，将日志记录添加到对应的日志列表中
            if (tm.isActive(xid)) {
                if (!logCache.containsKey(xid)) {
                    logCache.put(xid, new ArrayList<>());
                }
                logCache.get(xid).add(log);
            }
        } else {
            // 如果是更新日志，解析日志记录，获取更新日志信息
            UpdateLogInfo xi = parseUpdateLog(log);
            // 获取事务ID
            long xid = xi.xid;
            // 如果当前事务仍然活跃，将日志记录添加到对应的日志列表中
            if (tm.isActive(xid)) {
                if (!logCache.containsKey(xid)) {
                    logCache.put(xid, new ArrayList<>());
                }
                // 将事务id对应的log添加到集合中
                logCache.get(xid).add(log);
            }
        }
    }

    // 对所有活跃的事务的日志进行倒序撤销
    for (Entry<Long, List<byte[]>> entry : logCache.entrySet()) {
        List<byte[]> logs = entry.getValue();
        for (int i = logs.size() - 1; i >= 0; i--) {
            byte[] log = logs.get(i);
            // 判断日志记录的类型
            if (isInsertLog(log)) {
                // 如果是插入日志，进行撤销插入操作
                doInsertLog(pc, log, UNDO);
            } else {
                // 如果是更新日志，进行撤销更新操作
                doUpdateLog(pc, log, UNDO);
            }
        }
        // 中止当前事务
        tm.abort(entry.getKey());
    }
}
```
### doInsertLog()
以上两种事务的insert操作都是通过此方法完成
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/2b528188f0f68c134c118ffd08e9098d.png)
```java
private static void doInsertLog(PageCache pc, byte[] log, int flag) {
    // 解析日志记录，获取插入日志信息
    InsertLogInfo li = parseInsertLog(log);
    Page pg = null;
    try {
        // 根据页码从页面缓存中获取页面，即AbstractCache.get()方法
        pg = pc.getPage(li.pgno);
    } catch (Exception e) {
        // 如果发生异常，调用Panic.panic方法处理
        Panic.panic(e);
    }
    try {
        // 如果标志位为UNDO，将数据项设置为无效
        if (flag == UNDO) {
            DataItem.setDataItemRawInvalid(li.raw);
        }
        // 在指定的页面和偏移量处插入数据
        PageX.recoverInsert(pg, li.raw, li.offset);
    } finally {
        // 无论是否发生异常，都要释放页面,即AbstractCache.release() 方法
        pg.release();
    }
}
```
### doUpdateLog()
![](https://raw.githubusercontent.com/choodsire666/blog-img/main/日志文件/cd58aed9ae41da11825098ac36320fa0.png)
```java
private static void doUpdateLog(PageCache pc, byte[] log, int flag) {
    int pgno; // 用于存储页面编号
    short offset; // 用于存储偏移量
    byte[] raw; // 用于存储原始数据

    // 根据标志位判断是进行重做操作还是撤销操作
    if (flag == REDO) {
        // 如果是重做操作，解析日志记录，获取更新日志信息，主要获取新数据
        UpdateLogInfo xi = parseUpdateLog(log);
        pgno = xi.pgno;
        offset = xi.offset;
        raw = xi.newRaw;
    } else {
        // 如果是撤销操作，解析日志记录，获取更新日志信息，主要获取旧数据
        UpdateLogInfo xi = parseUpdateLog(log);
        pgno = xi.pgno;
        offset = xi.offset;
        raw = xi.oldRaw;
    }

    Page pg = null; // 用于存储获取到的页面
    try {
        // 尝试从页面缓存中获取指定页码的页面
        pg = pc.getPage(pgno);
    } catch (Exception e) {
        // 如果获取页面过程中发生异常，调用Panic.panic方法进行处理
        Panic.panic(e);
    }

    try {
        // 在指定的页面和偏移量处插入解析出的数据, 数据页缓存讲解了该方法
        PageX.recoverUpdate(pg, raw, offset);
    } finally {
        // 无论是否发生异常，都要释放页面
        pg.release();
    }
}
```
